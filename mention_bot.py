# mention_bot.py
# BOT ESPECIALIZADO EM RESPONDER MEN√á√ïES COM DISTRIBUI√á√ÉO INTELIGENTE DE TOKENS

import tweepy
import openai
import requests
import time
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, Optional, List
import hashlib

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('mention_bot.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Importa√ß√µes locais
from keys import *

class MentionBot:
    def __init__(self, my_username: str):
        """
        Inicializa o bot de men√ß√µes
        
        Args:
            my_username: Seu username no X (sem @), ex: "meuuser"
        """
        self.my_username = my_username.lower().replace('@', '')
        self.setup_clients()
        self.load_state()
        self.load_prompt_config()
        
    def setup_clients(self):
        """Configura clientes das APIs"""
        try:
            # Cliente OpenAI
            self.openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)
            
            # Cliente X/Twitter
            self.twitter_client = tweepy.Client(
                bearer_token=X_BEARER_TOKEN,
                consumer_key=X_API_KEY,
                consumer_secret=X_API_SECRET,
                access_token=X_ACCESS_TOKEN,
                access_token_secret=X_ACCESS_TOKEN_SECRET,
                wait_on_rate_limit=True
            )
            
            # Pega informa√ß√µes da pr√≥pria conta
            me = self.twitter_client.get_me()
            self.my_user_id = str(me.data.id)
            self.my_display_name = me.data.name
            
            logger.info(f"‚úÖ Bot inicializado para @{self.my_username} (ID: {self.my_user_id})")
            
        except Exception as e:
            logger.error(f"‚ùå Erro na inicializa√ß√£o: {e}")
            raise
    
    def load_state(self):
        """Carrega estado persistente do bot"""
        # Estat√≠sticas de uso dos modelos
        try:
            with open("model_usage_stats.json", "r") as f:
                self.model_stats = json.load(f)
        except FileNotFoundError:
            self.model_stats = {
                "chatgpt_uses": 0,
                "xai_uses": 0,
                "chatgpt_tokens": 0,
                "xai_tokens": 0,
                "last_reset": datetime.now().isoformat()
            }
        
        # Men√ß√µes j√° processadas
        try:
            with open("processed_mentions.json", "r") as f:
                self.processed_mentions = set(json.load(f))
        except FileNotFoundError:
            self.processed_mentions = set()
        
        # √öltimo ID de men√ß√£o processado
        try:
            with open("last_mention_id.json", "r") as f:
                data = json.load(f)
                self.last_mention_id = data.get("last_id")
        except FileNotFoundError:
            self.last_mention_id = None
    
    def save_state(self):
        """Salva estado persistente"""
        # Salva estat√≠sticas dos modelos
        with open("model_usage_stats.json", "w") as f:
            json.dump(self.model_stats, f, indent=2)
        
        # Salva men√ß√µes processadas
        with open("processed_mentions.json", "w") as f:
            json.dump(list(self.processed_mentions), f)
        
        # Salva √∫ltimo ID
        with open("last_mention_id.json", "w") as f:
            json.dump({"last_id": self.last_mention_id}, f)
    
    def load_prompt_config(self):
        """Carrega configura√ß√£o do prompt personalizado"""
        try:
            with open("mention_prompt_config.json", "r", encoding='utf-8') as f:
                self.prompt_config = json.load(f)
        except FileNotFoundError:
            # Cria configura√ß√£o padr√£o
            self.prompt_config = self.create_default_prompt_config()
            self.save_prompt_config()
    
    def create_default_prompt_config(self) -> Dict:
        """Cria configura√ß√£o padr√£o do prompt"""
        return {
            "base_personality": {
                "tone": "inteligente, respeitoso mas firme",
                "style": "direto e factual",
                "emotion": "equilibrado, nem muito formal nem muito casual",
                "max_length": 280
            },
            "core_beliefs": [
                "Defende a democracia e o Estado de Direito",
                "Valoriza dados e evid√™ncias cient√≠ficas",
                "Promove o di√°logo respeitoso e construtivo",
                "Questiona desinforma√ß√£o de forma educativa",
                "Apoia transpar√™ncia e accountability"
            ],
            "response_guidelines": [
                "Sempre pe√ßa fontes quando algu√©m faz afirma√ß√µes sem evid√™ncia",
                "Use dados oficiais quando dispon√≠veis (IBGE, TSE, etc.)",
                "Mantenha o foco no argumento, n√£o na pessoa",
                "Seja educativo, n√£o apenas cr√≠tico",
                "Evite linguagem ofensiva ou polarizante"
            ],
            "topics_expertise": {
                "politica": "Conhecimento profundo de institui√ß√µes e processos democr√°ticos",
                "economia": "Foco em dados oficiais e an√°lise t√©cnica",
                "ciencia": "Valoriza peer review e consenso cient√≠fico",
                "tecnologia": "Entende impactos sociais da tecnologia",
                "educacao": "Defende educa√ß√£o p√∫blica e de qualidade"
            },
            "context_awareness": {
                "check_tweet_context": True,
                "consider_thread": True,
                "analyze_sentiment": True,
                "detect_sarcasm": True
            },
            "custom_instructions": "Voc√™ representa uma voz da raz√£o no debate p√∫blico. Seja sempre construtivo, mesmo quando discorda. Seu objetivo √© elevar o n√≠vel do debate, n√£o vencer discuss√µes."
        }
    
    def save_prompt_config(self):
        """Salva configura√ß√£o do prompt"""
        with open("mention_prompt_config.json", "w", encoding='utf-8') as f:
            json.dump(self.prompt_config, f, indent=2, ensure_ascii=False)
    
    def choose_optimal_model(self) -> str:
        """
        Escolhe o modelo com base no uso anterior para distribuir tokens
        """
        chatgpt_uses = self.model_stats["chatgpt_uses"]
        xai_uses = self.model_stats["xai_uses"]
        
        # Se a diferen√ßa for muito grande, usa o menos utilizado
        if abs(chatgpt_uses - xai_uses) > 5:
            if chatgpt_uses < xai_uses:
                return "chatgpt"
            else:
                return "xai"
        
        # Se est√£o equilibrados, alterna baseado no hor√°rio
        hour = datetime.now().hour
        if hour % 2 == 0:
            return "chatgpt"
        else:
            return "xai"
    
    def build_context_prompt(self, mention_tweet: str, author_info: str, thread_context: str = "") -> str:
        """
        Constr√≥i o prompt completo com base na configura√ß√£o
        """
        config = self.prompt_config
        
        # Prompt base com personalidade
        base_prompt = f"""
Voc√™ √© um assistente inteligente que representa @{self.my_username} no X (Twitter).

PERSONALIDADE E TOM:
- Tom: {config['base_personality']['tone']}
- Estilo: {config['base_personality']['style']}  
- Emo√ß√£o: {config['base_personality']['emotion']}

VALORES FUNDAMENTAIS:
{chr(10).join(f"‚Ä¢ {belief}" for belief in config['core_beliefs'])}

DIRETRIZES DE RESPOSTA:
{chr(10).join(f"‚Ä¢ {guideline}" for guideline in config['response_guidelines'])}

INSTRU√á√ïES ESPECIAIS:
{config['custom_instructions']}

CONTEXTO DO TWEET:
Autor: {author_info}
Tweet que me mencionou: "{mention_tweet}"
{f"Contexto da conversa: {thread_context}" if thread_context else ""}

TAREFA:
Responda √† men√ß√£o de forma {config['base_personality']['tone']}, seguindo suas diretrizes.
M√°ximo de {config['base_personality']['max_length']} caracteres.
Seja relevante ao contexto e mantenha sua personalidade consistente.
"""
        
        return base_prompt.strip()
    
    def generate_response(self, mention_tweet: str, author_info: str, thread_context: str = "") -> Optional[str]:
        """
        Gera resposta usando o modelo escolhido
        """
        model_choice = self.choose_optimal_model()
        prompt = self.build_context_prompt(mention_tweet, author_info, thread_context)
        
        logger.info(f"ü§ñ Usando modelo: {model_choice}")
        
        try:
            if model_choice == "chatgpt":
                response = self.openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "Voc√™ √© um assistente especializado em responder men√ß√µes no X de forma inteligente e contextual."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=100,
                    temperature=0.7
                )
                
                comment = response.choices[0].message.content.strip()
                tokens_used = response.usage.total_tokens
                
                # Atualiza estat√≠sticas
                self.model_stats["chatgpt_uses"] += 1
                self.model_stats["chatgpt_tokens"] += tokens_used
                
            else:  # xAI
                headers = {
                    "Authorization": f"Bearer {XAI_API_KEY}",
                    "Content-Type": "application/json"
                }
                payload = {
                    "model": "grok-1",
                    "messages": [
                        {"role": "system", "content": "Voc√™ √© Grok, respondendo men√ß√µes de forma inteligente e com personalidade √∫nica."},
                        {"role": "user", "content": prompt}
                    ],
                    "max_tokens": 100,
                    "temperature": 0.7
                }
                
                response = requests.post(
                    "https://api.x.ai/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=30
                )
                response.raise_for_status()
                
                result = response.json()
                comment = result["choices"][0]["message"]["content"].strip()
                tokens_used = 100  # Estimativa para xAI
                
                # Atualiza estat√≠sticas
                self.model_stats["xai_uses"] += 1
                self.model_stats["xai_tokens"] += tokens_used
            
            logger.info(f"üí¨ Resposta gerada ({tokens_used} tokens): {comment[:50]}...")
            return comment
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar resposta com {model_choice}: {e}")
            return None
    
    def get_thread_context(self, tweet_id: str) -> str:
        """
        Obt√©m contexto da conversa (thread)
        """
        try:
            # Busca o tweet original se for uma resposta
            tweet = self.twitter_client.get_tweet(
                tweet_id, 
                tweet_fields=["conversation_id", "in_reply_to_user_id", "referenced_tweets"]
            )
            
            if tweet.data.referenced_tweets:
                # √â uma resposta, busca o tweet original
                original_id = tweet.data.referenced_tweets[0].id
                original = self.twitter_client.get_tweet(original_id)
                return f"Tweet original: {original.data.text[:100]}..."
            
            return ""
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  N√£o foi poss√≠vel obter contexto: {e}")
            return ""
    
    def check_mentions(self):
        """
        Verifica novas men√ß√µes e responde
        """
        logger.info("üîç Verificando novas men√ß√µes...")
        
        try:
            # Busca men√ß√µes recentes
            mentions = self.twitter_client.get_users_mentions(
                id=self.my_user_id,
                since_id=self.last_mention_id,
                max_results=10,
                tweet_fields=["created_at", "author_id", "conversation_id", "in_reply_to_user_id"],
                user_fields=["username", "name"]
            )
            
            if not mentions.data:
                logger.info("üì≠ Nenhuma men√ß√£o nova")
                return
            
            # Processa men√ß√µes em ordem cronol√≥gica
            mentions_list = sorted(mentions.data, key=lambda x: x.created_at)
            
            for mention in mentions_list:
                # Atualiza √∫ltimo ID processado
                self.last_mention_id = mention.id
                
                # Verifica se j√° foi processado
                if mention.id in self.processed_mentions:
                    continue
                
                # N√£o responde a si mesmo
                if str(mention.author_id) == self.my_user_id:
                    continue
                
                # Obt√©m informa√ß√µes do autor
                author = mentions.includes.get('users', [{}])[0]
                author_info = f"@{author.username} ({author.name})"
                
                logger.info(f"üì® Nova men√ß√£o de {author_info}: {mention.text}")
                
                # Obt√©m contexto da conversa
                thread_context = self.get_thread_context(mention.id)
                
                # Gera resposta
                response = self.generate_response(
                    mention.text, 
                    author_info, 
                    thread_context
                )
                
                if response:
                    # Posta resposta
                    try:
                        self.twitter_client.create_tweet(
                            text=response,
                            in_reply_to_tweet_id=mention.id
                        )
                        
                        logger.info(f"‚úÖ Resposta enviada para {author_info}")
                        
                    except Exception as e:
                        logger.error(f"‚ùå Erro ao postar resposta: {e}")
                
                # Marca como processado
                self.processed_mentions.add(mention.id)
                
                # Pausa entre respostas
                time.sleep(5)
            
            # Salva estado
            self.save_state()
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao verificar men√ß√µes: {e}")
    
    def get_usage_stats(self) -> Dict:
        """
        Retorna estat√≠sticas de uso dos modelos
        """
        total_uses = self.model_stats["chatgpt_uses"] + self.model_stats["xai_uses"]
        total_tokens = self.model_stats["chatgpt_tokens"] + self.model_stats["xai_tokens"]
        
        if total_uses == 0:
            return {"message": "Nenhuma resposta gerada ainda"}
        
        return {
            "total_responses": total_uses,
            "total_tokens": total_tokens,
            "chatgpt": {
                "uses": self.model_stats["chatgpt_uses"],
                "tokens": self.model_stats["chatgpt_tokens"],
                "percentage": (self.model_stats["chatgpt_uses"] / total_uses) * 100
            },
            "xai": {
                "uses": self.model_stats["xai_uses"], 
                "tokens": self.model_stats["xai_tokens"],
                "percentage": (self.model_stats["xai_uses"] / total_uses) * 100
            },
            "balance": abs(self.model_stats["chatgpt_uses"] - self.model_stats["xai_uses"])
        }
    
    def run(self):
        """
        Loop principal do bot
        """
        logger.info(f"üöÄ Bot de men√ß√µes iniciado para @{self.my_username}")
        
        while True:
            try:
                self.check_mentions()
                
                # Mostra estat√≠sticas a cada 10 verifica√ß√µes
                if hasattr(self, '_check_count'):
                    self._check_count += 1
                else:
                    self._check_count = 1
                
                if self._check_count % 10 == 0:
                    stats = self.get_usage_stats()
                    if "total_responses" in stats:
                        logger.info(f"üìä Stats: {stats['total_responses']} respostas, "
                                  f"ChatGPT: {stats['chatgpt']['percentage']:.1f}%, "
                                  f"xAI: {stats['xai']['percentage']:.1f}%")
                
                # Pr√≥xima verifica√ß√£o em 2 minutos
                next_check = datetime.now() + timedelta(minutes=2)
                logger.info(f"üò¥ Pr√≥xima verifica√ß√£o √†s {next_check.strftime('%H:%M:%S')}")
                
                time.sleep(120)  # 2 minutos
                
            except KeyboardInterrupt:
                logger.info("üëã Bot encerrado pelo usu√°rio")
                self.save_state()
                break
                
            except Exception as e:
                logger.error(f"‚ùå Erro inesperado: {e}")
                time.sleep(300)  # 5 minutos em caso de erro

def main():
    """
    Fun√ß√£o principal - solicita username e inicia o bot
    """
    print("ü§ñ BOT DE MEN√á√ïES X.COM")
    print("=" * 30)
    
    # Solicita username
    username = input("Digite seu username do X (sem @): ").strip()
    
    if not username:
        print("‚ùå Username √© obrigat√≥rio!")
        return
    
    try:
        bot = MentionBot(username)
        bot.run()
    except Exception as e:
        print(f"‚ùå Erro ao iniciar bot: {e}")

if __name__ == "__main__":
    main()